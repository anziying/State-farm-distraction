{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84286ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751474f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "script = 'abcd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86a0937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from myXception import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef804e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script Started\n"
     ]
    }
   ],
   "source": [
    "rng_seed = 507\n",
    "torch.manual_seed(rng_seed)\n",
    "print('Script Started')\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    \"\"\"\n",
    "    :param folder: The folder that loads images\n",
    "    :return: a list of ndarray-type images\n",
    "    You can use this function to load all images in a certain folder into a list of np.ndarray\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "\n",
    "def load_images_from_folder_10_class(folder):\n",
    "    \"\"\"\n",
    "    :param folder: The folder that loads images\n",
    "    :return: image, labels\n",
    "    Set \"folder\" as the path of training dataset (e.g. \"distraction_data/imgs/train\").\n",
    "    There should be ten folders (c0-c9) under the path.\n",
    "    The function returns images in a list of np.ndarray and a list of classification labels.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_list = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    for idx in range(len(class_list)):\n",
    "        sub_folder = os.path.join(folder, class_list[idx])\n",
    "        for filename in os.listdir(sub_folder):\n",
    "            img = cv2.imread(os.path.join(sub_folder, filename))\n",
    "            if img is not None:\n",
    "                img_frame = np.zeros((3, 480, 640))\n",
    "                img_frame[0, :, :] = img[:, :, 0]\n",
    "                img_frame[1, :, :] = img[:, :, 1]\n",
    "                img_frame[2, :, :] = img[:, :, 2]\n",
    "                images.append(img_frame)\n",
    "                labels.append(np.array([idx], dtype=np.longlong))\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Set your path of training dataset here\n",
    "\"\"\"\n",
    "\n",
    "train_dataset_folder = r\"distraction_data/imgs/train\"\n",
    "# train_dataset_folder = r\"small_dataset/imgs/train\"\n",
    "\n",
    "\"\"\"\n",
    "Comment out the following snippet if you have your.pt files of images and labels in the root of directory. \n",
    "\"\"\"\n",
    "############################Training set#############################\n",
    "\n",
    "# train_imgs, train_labels = load_images_from_folder_10_class(train_dataset_folder)\n",
    "# tensor_x_train = torch.Tensor(train_imgs) # transform to torch tensor\n",
    "# tensor_y_train = torch.Tensor(train_labels)\n",
    "\n",
    "# torch.save(tensor_x_train, 'training_image_tensor_7_8.pt')\n",
    "# torch.save(tensor_y_train, 'training_label_tensor_7_8.pt')\n",
    "\n",
    "#############################Testing set#############################\n",
    "\n",
    "# test_dataset_folder = r\"small_test\"\n",
    "#\n",
    "# test_imgs, test_labels = load_images_from_folder_10_class(test_dataset_folder)\n",
    "# tensor_x_test = torch.Tensor(test_imgs) # transform to torch tensor\n",
    "# tensor_y_test = torch.Tensor(test_labels)\n",
    "#\n",
    "# torch.save(tensor_x_test, 'testing_image_tensor_7_8.pt')\n",
    "# torch.save(tensor_y_test, 'testing_label_tensor_7_8.pt')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The following code loads the saved torch.Tensor file into a Dataloader\n",
    "\"\"\"\n",
    "\n",
    "tensor_x_train = torch.load('training_image_tensor_7_8.pt')\n",
    "tensor_y_train = torch.load('training_label_tensor_7_8.pt')\n",
    "# tensor_x_test = torch.load('testing_image_tensor_7_8.pt')\n",
    "# tensor_y_test = torch.load('testing_label_tensor_7_8.pt')\n",
    "\n",
    "train_dataset = TensorDataset(tensor_x_train, tensor_y_train)  # create your datset\n",
    "\n",
    "def loadData(dataset, test_percentage, batch):\n",
    "    dataset_size = len(dataset)\n",
    "    test_size = int(test_percentage * dataset_size)\n",
    "    train_size = dataset_size - test_size\n",
    "    train_dataset, test_dataset = random_split(dataset,\n",
    "                                               [train_size, test_size])\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset.dataset,\n",
    "        batch_size=batch,\n",
    "        shuffle=True)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset.dataset,\n",
    "        batch_size=batch,\n",
    "        shuffle=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader, test_dataloader = loadData(train_dataset, 0.3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ecc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = TensorDataset(tensor_x_test, tensor_y_test)  # create your datset\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=True)  # create your dataloader\n",
    "\n",
    "print(\"Going to train...\")\n",
    "\n",
    "def conv_out_size(slen, kernel_size, stride):\n",
    "    \"\"\"\n",
    "    :param slen: Size length of the image. Should be an int.\n",
    "    :param kernel_size: Int\n",
    "    :param stride: Int\n",
    "    :return: The size length of output after convolution\n",
    "    This function considers 1-dim case.\n",
    "    \"\"\"\n",
    "    return int((slen - kernel_size) / stride + 1)\n",
    "\n",
    "\n",
    "def train_loop(model, transform_fn, loss_fn, optimizer, dataloader, num_epochs):\n",
    "    \"\"\"\n",
    "\n",
    "    :param model:\n",
    "    :param transform_fn:\n",
    "    :param loss_fn:\n",
    "    :param optimizer:\n",
    "    :param dataloader:\n",
    "    :param num_epochs:\n",
    "    :return:\n",
    "\n",
    "    Use this function to train your model.\n",
    "    \"\"\"\n",
    "    tbar = tqdm(range(num_epochs))\n",
    "    for _ in tbar:\n",
    "        loss_total = 0.\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            x = transform_fn(x)\n",
    "            pred = model(x)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            loss = loss_fn(pred, y.squeeze(-1))\n",
    "            # print(pred)\n",
    "            # print(y.squeeze(-1))\n",
    "            ## Parameter updates\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_total += loss.item()\n",
    "        tbar.set_description(f\"Train loss: {loss_total / len(dataloader)}\")\n",
    "\n",
    "    return loss_total / len(dataloader)\n",
    "\n",
    "\n",
    "def calculate_test_accuracy(model, transform_fn, dataloader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    tf = nn.Flatten()\n",
    "    for (xi, yi) in dataloader:\n",
    "        xi = transform_fn(xi)\n",
    "        pred = model(xi)\n",
    "        yi_pred = pred.argmax(-1)\n",
    "        y_true.append(yi)\n",
    "        y_pred.append(yi_pred)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "\n",
    "    accuracy = (y_true.squeeze(-1) == y_pred).float().mean()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def calculate_log_loss(model, dataloader):\n",
    "    log_list = []\n",
    "    for (xi, yi) in dataloader:\n",
    "        pred = model(xi)\n",
    "        pred_np = pred.cpu().detach().numpy()\n",
    "        yi_np = yi.cpu().detach().numpy()\n",
    "        logs = np.choose(yi_np.reshape(-1).astype(int), pred_np.T)\n",
    "        log_list.append(np.mean(logs))\n",
    "    return np.mean(np.array(log_list))\n",
    "\n",
    "\n",
    "convnet = Xception_Network(480, 640, num_classes=10)\n",
    "\n",
    "convnet_optimizer = torch.optim.Adam(convnet.parameters(), lr=0.0002)\n",
    "\n",
    "\n",
    "def s(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "loss_functions = [torch.nn.CrossEntropyLoss(), nn.NLLLoss()]\n",
    "\n",
    "train_loop(convnet, s, loss_functions[0], convnet_optimizer, train_dataloader, 10)\n",
    "\n",
    "acc = calculate_test_accuracy(convnet, s, test_dataloader)\n",
    "\n",
    "log_loss = calculate_log_loss(convnet, test_dataloader)\n",
    "\n",
    "print(acc)\n",
    "print(log_loss)\n",
    "\n",
    "test_folder = r\"distraction_data/imgs/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = TensorDataset(tensor_x_test, tensor_y_test)  # create your datset\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=True)  # create your dataloader\n",
    "\n",
    "print(\"Going to train...\")\n",
    "\n",
    "def conv_out_size(slen, kernel_size, stride):\n",
    "    \"\"\"\n",
    "    :param slen: Size length of the image. Should be an int.\n",
    "    :param kernel_size: Int\n",
    "    :param stride: Int\n",
    "    :return: The size length of output after convolution\n",
    "    This function considers 1-dim case.\n",
    "    \"\"\"\n",
    "    return int((slen - kernel_size) / stride + 1)\n",
    "\n",
    "\n",
    "def train_loop(model, transform_fn, loss_fn, optimizer, dataloader, num_epochs):\n",
    "    \"\"\"\n",
    "\n",
    "    :param model:\n",
    "    :param transform_fn:\n",
    "    :param loss_fn:\n",
    "    :param optimizer:\n",
    "    :param dataloader:\n",
    "    :param num_epochs:\n",
    "    :return:\n",
    "\n",
    "    Use this function to train your model.\n",
    "    \"\"\"\n",
    "    tbar = tqdm(range(num_epochs))\n",
    "    for _ in tbar:\n",
    "        loss_total = 0.\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            x = transform_fn(x)\n",
    "            pred = model(x)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            loss = loss_fn(pred, y.squeeze(-1))\n",
    "            # print(pred)\n",
    "            # print(y.squeeze(-1))\n",
    "            ## Parameter updates\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_total += loss.item()\n",
    "        tbar.set_description(f\"Train loss: {loss_total / len(dataloader)}\")\n",
    "\n",
    "    return loss_total / len(dataloader)\n",
    "\n",
    "\n",
    "def calculate_test_accuracy(model, transform_fn, dataloader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    tf = nn.Flatten()\n",
    "    for (xi, yi) in dataloader:\n",
    "        xi = transform_fn(xi)\n",
    "        pred = model(xi)\n",
    "        yi_pred = pred.argmax(-1)\n",
    "        y_true.append(yi)\n",
    "        y_pred.append(yi_pred)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "\n",
    "    accuracy = (y_true.squeeze(-1) == y_pred).float().mean()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def calculate_log_loss(model, dataloader):\n",
    "    log_list = []\n",
    "    for (xi, yi) in dataloader:\n",
    "        pred = model(xi)\n",
    "        pred_np = pred.cpu().detach().numpy()\n",
    "        yi_np = yi.cpu().detach().numpy()\n",
    "        logs = np.choose(yi_np.reshape(-1).astype(int), pred_np.T)\n",
    "        log_list.append(np.mean(logs))\n",
    "    return np.mean(np.array(log_list))\n",
    "\n",
    "\n",
    "convnet = Xception_Network(480, 640, num_classes=10)\n",
    "\n",
    "convnet_optimizer = torch.optim.Adam(convnet.parameters(), lr=0.0002)\n",
    "\n",
    "\n",
    "def s(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "loss_functions = [torch.nn.CrossEntropyLoss(), nn.NLLLoss()]\n",
    "\n",
    "train_loop(convnet, s, loss_functions[0], convnet_optimizer, train_dataloader, 10)\n",
    "\n",
    "acc = calculate_test_accuracy(convnet, s, test_dataloader)\n",
    "\n",
    "log_loss = calculate_log_loss(convnet, test_dataloader)\n",
    "\n",
    "print(acc)\n",
    "print(log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01644ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1835109/941796882.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  test_x = torch.Tensor([img_frame])\n"
     ]
    }
   ],
   "source": [
    "test_folder = r\"distraction_data/imgs/test\"\n",
    "\n",
    "\n",
    "def predict_images_in_folder(folder, model):\n",
    "    prediction_list = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            img_frame = np.zeros((3, 480, 640))\n",
    "            img_frame[0, :, :] = img[:, :, 0]\n",
    "            img_frame[1, :, :] = img[:, :, 1]\n",
    "            img_frame[2, :, :] = img[:, :, 2]\n",
    "            test_x = torch.Tensor([img_frame])\n",
    "            pred_x = model(test_x)\n",
    "            pred_x = pred_x.cpu().detach().numpy()\n",
    "            pred_x = np.exp(pred_x)\n",
    "            prediction_list.append((filename, pred_x[0].tolist()))\n",
    "    prediction_list = sorted(prediction_list, key=lambda x: x[0])\n",
    "    return prediction_list\n",
    "\n",
    "\n",
    "result = predict_images_in_folder(test_folder, convnet)\n",
    "result = [[x[0], x[1][0], x[1][1], x[1][2], x[1][3], x[1][4], x[1][5], x[1][6], x[1][7], x[1][8], x[1][9]]\n",
    "             for x in result]\n",
    "\n",
    "result_df = pandas.DataFrame(result, columns=['img', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "result_df.set_index('img')\n",
    "result_df.to_csv('submission.csv')\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac1e422c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68b67e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(convnet.state_dict(), 'net_7_14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "027de42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(convnet.state_dict(), 'net_7_14.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed073569",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            \n",
    "            'model_state_dict': convnet.state_dict(),\n",
    "            \n",
    "            }, 'state_dict_7_14.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "545427a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Xception_Network(\n",
       "  (pre_conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (pre_relu1): ReLU(inplace=True)\n",
       "  (pre_conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (pre_relu2): ReLU(inplace=True)\n",
       "  (entry_block1): EntryFlowBlock(\n",
       "    (net): Sequential(\n",
       "      (0): SeparableConv2d(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "        (conv2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): SeparableConv2d(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "  )\n",
       "  (entry_block2): EntryFlowBlock(\n",
       "    (net): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "        (conv2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): SeparableConv2d(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (4): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "  )\n",
       "  (entry_block3): EntryFlowBlock(\n",
       "    (net): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (conv2): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (4): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2))\n",
       "  )\n",
       "  (middle_block1): MiddleFlowBlock(\n",
       "    (net): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block2): MiddleFlowBlock(\n",
       "    (net): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block3): MiddleFlowBlock(\n",
       "    (net): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block4): MiddleFlowBlock(\n",
       "    (net): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block5): MiddleFlowBlock(\n",
       "    (net): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block6): MiddleFlowBlock(\n",
       "    (net): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block7): MiddleFlowBlock(\n",
       "    (net): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block8): MiddleFlowBlock(\n",
       "    (net): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (exit_block): ExitFlowBlock(\n",
       "    (net): Sequential(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): SeparableConv2d(\n",
       "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "        (conv2): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (4): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (conv): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
       "  )\n",
       "  (post_conv1): SeparableConv2d(\n",
       "    (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "    (conv2): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (post_relu1): ReLU()\n",
       "  (post_conv2): SeparableConv2d(\n",
       "    (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "    (conv2): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (post_relu2): ReLU()\n",
       "  (average_pool): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
       "  (ln): Linear(in_features=61440, out_features=10, bias=True)\n",
       "  (sm): LogSoftmax(dim=-1)\n",
       "  (net): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): EntryFlowBlock(\n",
       "      (net): Sequential(\n",
       "        (0): SeparableConv2d(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (conv2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): SeparableConv2d(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "    )\n",
       "    (5): EntryFlowBlock(\n",
       "      (net): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (conv2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): SeparableConv2d(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (4): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "    )\n",
       "    (6): EntryFlowBlock(\n",
       "      (net): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (conv2): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (4): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2))\n",
       "    )\n",
       "    (7): MiddleFlowBlock(\n",
       "      (net): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): MiddleFlowBlock(\n",
       "      (net): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): MiddleFlowBlock(\n",
       "      (net): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): MiddleFlowBlock(\n",
       "      (net): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): MiddleFlowBlock(\n",
       "      (net): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): MiddleFlowBlock(\n",
       "      (net): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): MiddleFlowBlock(\n",
       "      (net): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): MiddleFlowBlock(\n",
       "      (net): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): ExitFlowBlock(\n",
       "      (net): Sequential(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): SeparableConv2d(\n",
       "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (conv2): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (4): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=1, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (conv): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
       "    )\n",
       "    (16): SeparableConv2d(\n",
       "      (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "      (conv2): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (17): ReLU()\n",
       "    (18): SeparableConv2d(\n",
       "      (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "      (conv2): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (19): ReLU()\n",
       "    (20): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
       "    (21): Flatten(start_dim=1, end_dim=-1)\n",
       "    (22): Linear(in_features=61440, out_features=10, bias=True)\n",
       "    (23): LogSoftmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convnet = Xception_Network(480, 640, num_classes=10)\n",
    "convnet.load_state_dict(torch.load('net_7_14'), strict=False)\n",
    "convnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c10a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
