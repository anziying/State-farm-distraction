{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13b98563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# test_zip = zipfile.ZipFile(r\"distraction_data/imgs/test.zip\", \"r\" )\n",
    "# for fileM in test_zip.namelist():\n",
    "#     test_zip.extract(fileM, \"distraction_data/imgs\")\n",
    "# test_zip.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e843d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n",
    "rng_seed = 507\n",
    "torch.manual_seed(rng_seed)\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    \"\"\"\n",
    "    :param folder: The folder that loads images\n",
    "    :return: a list of ndarray-type images\n",
    "    You can use this function to load all images in a certain folder into a list of np.ndarray\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "\n",
    "def load_images_from_folder_10_class(folder):\n",
    "    \"\"\"\n",
    "    :param folder: The folder that loads images\n",
    "    :return: image, labels\n",
    "    Set \"folder\" as the path of training dataset (e.g. \"distraction_data/imgs/train\").\n",
    "    There should be ten folders (c0-c9) under the path.\n",
    "    The function returns images in a list of np.ndarray and a list of classification labels.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_list = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    for idx in range(len(class_list)):\n",
    "        sub_folder = os.path.join(folder, class_list[idx])\n",
    "        for filename in os.listdir(sub_folder):\n",
    "            img = cv2.imread(os.path.join(sub_folder, filename))\n",
    "            if img is not None:\n",
    "                img_frame = np.zeros((3, 480, 640))\n",
    "                img_frame[0, :, :] = img[:, :, 0]\n",
    "                img_frame[1, :, :] = img[:, :, 1]\n",
    "                img_frame[2, :, :] = img[:, :, 2]\n",
    "                images.append(img_frame)\n",
    "                labels.append(np.array([idx], dtype=int))\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Set your path of training dataset here\n",
    "\"\"\"\n",
    "\n",
    "# train_dataset_folder = r\"distraction_data/imgs/train\"\n",
    "train_dataset_folder = r\"small_dataset/imgs/train\"\n",
    "\n",
    "\"\"\"\n",
    "Comment out the following snippet if you have your.pt files of images and labels in the root of directory. \n",
    "\"\"\"\n",
    "############################Training set#############################\n",
    "\n",
    "# train_imgs, train_labels = load_images_from_folder_10_class(train_dataset_folder)\n",
    "# tensor_x_train = torch.Tensor(train_imgs) # transform to torch tensor\n",
    "# tensor_y_train = torch.Tensor(train_labels)\n",
    "#\n",
    "# torch.save(tensor_x_train, 'training_image_tensor_7_8.pt')\n",
    "# torch.save(tensor_y_train, 'training_label_tensor_7_8.pt')\n",
    "\n",
    "#############################Testing set#############################\n",
    "\n",
    "# test_dataset_folder = r\"small_test\"\n",
    "#\n",
    "# test_imgs, test_labels = load_images_from_folder_10_class(test_dataset_folder)\n",
    "# tensor_x_test = torch.Tensor(test_imgs) # transform to torch tensor\n",
    "# tensor_y_test = torch.Tensor(test_labels)\n",
    "#\n",
    "# torch.save(tensor_x_test, 'testing_image_tensor_7_8.pt')\n",
    "# torch.save(tensor_y_test, 'testing_label_tensor_7_8.pt')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The following code loads the saved torch.Tensor file into a Dataloader\n",
    "\"\"\"\n",
    "\n",
    "tensor_x_train = torch.load('training_image_tensor_7_8.pt')\n",
    "tensor_y_train = torch.load('training_label_tensor_7_8.pt')\n",
    "# tensor_x_test = torch.load('testing_image_tensor_7_8.pt')\n",
    "# tensor_y_test = torch.load('testing_label_tensor_7_8.pt')\n",
    "\n",
    "train_dataset = TensorDataset(tensor_x_train, tensor_y_train)  # create your datset\n",
    "\n",
    "def loadData(dataset, test_percentage, batch):\n",
    "    dataset_size = len(dataset)\n",
    "    test_size = int(test_percentage * dataset_size)\n",
    "    train_size = dataset_size - test_size\n",
    "    train_dataset, test_dataset = random_split(dataset,\n",
    "                                               [train_size, test_size])\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset.dataset,\n",
    "        batch_size=batch,\n",
    "        shuffle=True)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset.dataset,\n",
    "        batch_size=batch,\n",
    "        shuffle=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader, test_dataloader = loadData(train_dataset, 0.3, 100)\n",
    "\n",
    "# test_dataset = TensorDataset(tensor_x_test, tensor_y_test)  # create your datset\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=True)  # create your dataloader\n",
    "\n",
    "\n",
    "def conv_out_size(slen, kernel_size, stride):\n",
    "    \"\"\"\n",
    "    :param slen: Size length of the image. Should be an int.\n",
    "    :param kernel_size: Int\n",
    "    :param stride: Int\n",
    "    :return: The size length of output after convolution\n",
    "    This function considers 1-dim case.\n",
    "    \"\"\"\n",
    "    return int((slen - kernel_size) / stride + 1)\n",
    "\n",
    "\n",
    "class MultiClassConvNet(torch.nn.Module):\n",
    "    def __init__(self, image_size_tup, num_classes):\n",
    "        \"\"\"\n",
    "        :param image_size_tup: should be (480, 640) in this project\n",
    "        :param num_classes: 10\n",
    "        This is a naive example of CNN. Please feel free to modify its stucture.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.kernel_size = 3\n",
    "\n",
    "        self.conv1 = (conv_out_size(image_size_tup[0], self.kernel_size, 1),\n",
    "                      conv_out_size(image_size_tup[1], self.kernel_size, 1))\n",
    "        self.maxpool1 = (conv_out_size(self.conv1[0], self.kernel_size, 1),\n",
    "                         conv_out_size(self.conv1[1], self.kernel_size, 1))\n",
    "        self.conv2 = (conv_out_size(self.maxpool1[0], self.kernel_size, 1),\n",
    "                      conv_out_size(self.maxpool1[1], self.kernel_size, 1))\n",
    "        self.maxpool2 = (conv_out_size(self.conv2[0], self.kernel_size, 1),\n",
    "                         conv_out_size(self.conv2[1], self.kernel_size, 1))\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3,\n",
    "                      3,\n",
    "                      kernel_size=self.kernel_size,\n",
    "                      stride=1\n",
    "                      ),\n",
    "            nn.MaxPool2d(kernel_size=self.kernel_size, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(3, 1, kernel_size=self.kernel_size),\n",
    "            nn.MaxPool2d(kernel_size=self.kernel_size, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1 * (self.maxpool2[0] * self.maxpool2[1]), 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def train_loop(model, transform_fn, loss_fn, optimizer, dataloader, num_epochs):\n",
    "    \"\"\"\n",
    "\n",
    "    :param model:\n",
    "    :param transform_fn:\n",
    "    :param loss_fn:\n",
    "    :param optimizer:\n",
    "    :param dataloader:\n",
    "    :param num_epochs:\n",
    "    :return:\n",
    "\n",
    "    Use this function to train your model.\n",
    "    \"\"\"\n",
    "    tbar = tqdm(range(num_epochs))\n",
    "    for _ in tbar:\n",
    "        loss_total = 0.\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            x = transform_fn(x)\n",
    "\n",
    "            pred = model(x)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            loss = loss_fn(pred, y.squeeze(-1))\n",
    "            # print(pred)\n",
    "            # print(y.squeeze(-1))\n",
    "            ## Parameter updates\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_total += loss.item()\n",
    "        tbar.set_description(f\"Train loss: {loss_total / len(dataloader)}\")\n",
    "\n",
    "    return loss_total / len(dataloader)\n",
    "\n",
    "\n",
    "def calculate_test_accuracy(model, transform_fn, test_dataloader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    tf = nn.Flatten()\n",
    "    for (xi, yi) in test_dataloader:\n",
    "        xi = transform_fn(xi)\n",
    "        pred = model(xi)\n",
    "        yi_pred = pred.argmax(-1)\n",
    "        y_true.append(yi)\n",
    "        y_pred.append(yi_pred)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "\n",
    "    accuracy = (y_true.squeeze(-1) == y_pred).float().mean()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def calculate_log_loss(model, dataloader):\n",
    "    log_list = []\n",
    "    for (xi, yi) in dataloader:\n",
    "        pred = model(xi)\n",
    "        pred_np = pred.cpu().detach().numpy()\n",
    "        yi_np = yi.cpu().detach().numpy()\n",
    "        logs = np.choose(yi_np.reshape(-1).astype(int), pred_np.T)\n",
    "        log_list.append(np.mean(logs))\n",
    "    return np.mean(np.array(log_list))\n",
    "\n",
    "\n",
    "convnet = MultiClassConvNet(image_size_tup=(480, 640), num_classes=10)\n",
    "\n",
    "convnet_optimizer = torch.optim.Adam(convnet.parameters(), lr=0.0002)\n",
    "\n",
    "\n",
    "def s(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "loss_functions = [torch.nn.CrossEntropyLoss(), nn.NLLLoss()]\n",
    "\n",
    "train_loop(convnet, s, loss_functions[0], convnet_optimizer, train_dataloader, 10)\n",
    "\n",
    "acc = calculate_test_accuracy(convnet, s, test_dataloader)\n",
    "\n",
    "log_loss = calculate_log_loss(convnet, test_dataloader)\n",
    "\n",
    "print(acc)\n",
    "print(log_loss)\n",
    "\n",
    "pass\n",
    "\n",
    "# test_folder = r\"distraction_data/imgs/test\"\n",
    "test_folder = r\"distraction_data/imgs/small_test\"\n",
    "# test_folder = r\"distraction_data/imgs/train/c0\"\n",
    "\n",
    "\n",
    "def predict_images_in_folder(folder, model):\n",
    "    prediction_list = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            img_frame = np.zeros((3, 480, 640))\n",
    "            img_frame[0, :, :] = img[:, :, 0]\n",
    "            img_frame[1, :, :] = img[:, :, 1]\n",
    "            img_frame[2, :, :] = img[:, :, 2]\n",
    "            test_x = torch.Tensor(img_frame)\n",
    "            pred_x = model(test_x)\n",
    "            pred_x = pred_x.cpu().detach().numpy()\n",
    "            pred_x = np.exp(pred_x)\n",
    "            prediction_list.append((filename, pred_x[0].tolist()))\n",
    "    prediction_list = sorted(prediction_list, key=lambda x: x[0])\n",
    "    return prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5938914",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict_images_in_folder(test_folder, convnet)\n",
    "result = [[x[0], x[1][0], x[1][1], x[1][2], x[1][3], x[1][4], x[1][5], x[1][6], x[1][7], x[1][8], x[1][9]]\n",
    "             for x in result]\n",
    "\n",
    "result_df = pandas.DataFrame(result, columns=['img', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "result_df.set_index('img')\n",
    "result_df.to_csv('submission.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeadd7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f47631e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
