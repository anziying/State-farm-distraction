{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84286ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751474f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "script = 'abcd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef804e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script Started\n"
     ]
    }
   ],
   "source": [
    "from myXception import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n",
    "rng_seed = 507\n",
    "torch.manual_seed(rng_seed)\n",
    "print('Script Started')\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    \"\"\"\n",
    "    :param folder: The folder that loads images\n",
    "    :return: a list of ndarray-type images\n",
    "    You can use this function to load all images in a certain folder into a list of np.ndarray\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "\n",
    "def load_images_from_folder_10_class(folder):\n",
    "    \"\"\"\n",
    "    :param folder: The folder that loads images\n",
    "    :return: image, labels\n",
    "    Set \"folder\" as the path of training dataset (e.g. \"distraction_data/imgs/train\").\n",
    "    There should be ten folders (c0-c9) under the path.\n",
    "    The function returns images in a list of np.ndarray and a list of classification labels.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_list = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    for idx in range(len(class_list)):\n",
    "        sub_folder = os.path.join(folder, class_list[idx])\n",
    "        for filename in os.listdir(sub_folder):\n",
    "            img = cv2.imread(os.path.join(sub_folder, filename))\n",
    "            if img is not None:\n",
    "                img_frame = np.zeros((3, 480, 640))\n",
    "                img_frame[0, :, :] = img[:, :, 0]\n",
    "                img_frame[1, :, :] = img[:, :, 1]\n",
    "                img_frame[2, :, :] = img[:, :, 2]\n",
    "                images.append(img_frame)\n",
    "                labels.append(np.array([idx], dtype=np.longlong))\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Set your path of training dataset here\n",
    "\"\"\"\n",
    "\n",
    "train_dataset_folder = r\"distraction_data/imgs/train\"\n",
    "# train_dataset_folder = r\"small_dataset/imgs/train\"\n",
    "\n",
    "\"\"\"\n",
    "Comment out the following snippet if you have your.pt files of images and labels in the root of directory. \n",
    "\"\"\"\n",
    "############################Training set#############################\n",
    "\n",
    "# train_imgs, train_labels = load_images_from_folder_10_class(train_dataset_folder)\n",
    "# tensor_x_train = torch.Tensor(train_imgs) # transform to torch tensor\n",
    "# tensor_y_train = torch.Tensor(train_labels)\n",
    "\n",
    "# torch.save(tensor_x_train, 'training_image_tensor_7_8.pt')\n",
    "# torch.save(tensor_y_train, 'training_label_tensor_7_8.pt')\n",
    "\n",
    "#############################Testing set#############################\n",
    "\n",
    "# test_dataset_folder = r\"small_test\"\n",
    "#\n",
    "# test_imgs, test_labels = load_images_from_folder_10_class(test_dataset_folder)\n",
    "# tensor_x_test = torch.Tensor(test_imgs) # transform to torch tensor\n",
    "# tensor_y_test = torch.Tensor(test_labels)\n",
    "#\n",
    "# torch.save(tensor_x_test, 'testing_image_tensor_7_8.pt')\n",
    "# torch.save(tensor_y_test, 'testing_label_tensor_7_8.pt')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The following code loads the saved torch.Tensor file into a Dataloader\n",
    "\"\"\"\n",
    "\n",
    "tensor_x_train = torch.load('training_image_tensor_7_8.pt')\n",
    "tensor_y_train = torch.load('training_label_tensor_7_8.pt')\n",
    "# tensor_x_test = torch.load('testing_image_tensor_7_8.pt')\n",
    "# tensor_y_test = torch.load('testing_label_tensor_7_8.pt')\n",
    "\n",
    "train_dataset = TensorDataset(tensor_x_train, tensor_y_train)  # create your datset\n",
    "\n",
    "def loadData(dataset, test_percentage, batch):\n",
    "    dataset_size = len(dataset)\n",
    "    test_size = int(test_percentage * dataset_size)\n",
    "    train_size = dataset_size - test_size\n",
    "    train_dataset, test_dataset = random_split(dataset,\n",
    "                                               [train_size, test_size])\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset.dataset,\n",
    "        batch_size=batch,\n",
    "        shuffle=True)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset.dataset,\n",
    "        batch_size=batch,\n",
    "        shuffle=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader, test_dataloader = loadData(train_dataset, 0.3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ecc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = TensorDataset(tensor_x_test, tensor_y_test)  # create your datset\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=True)  # create your dataloader\n",
    "\n",
    "print(\"Going to train...\")\n",
    "\n",
    "def conv_out_size(slen, kernel_size, stride):\n",
    "    \"\"\"\n",
    "    :param slen: Size length of the image. Should be an int.\n",
    "    :param kernel_size: Int\n",
    "    :param stride: Int\n",
    "    :return: The size length of output after convolution\n",
    "    This function considers 1-dim case.\n",
    "    \"\"\"\n",
    "    return int((slen - kernel_size) / stride + 1)\n",
    "\n",
    "\n",
    "def train_loop(model, transform_fn, loss_fn, optimizer, dataloader, num_epochs):\n",
    "    \"\"\"\n",
    "\n",
    "    :param model:\n",
    "    :param transform_fn:\n",
    "    :param loss_fn:\n",
    "    :param optimizer:\n",
    "    :param dataloader:\n",
    "    :param num_epochs:\n",
    "    :return:\n",
    "\n",
    "    Use this function to train your model.\n",
    "    \"\"\"\n",
    "    tbar = tqdm(range(num_epochs))\n",
    "    for _ in tbar:\n",
    "        loss_total = 0.\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            x = transform_fn(x)\n",
    "            pred = model(x)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            loss = loss_fn(pred, y.squeeze(-1))\n",
    "            # print(pred)\n",
    "            # print(y.squeeze(-1))\n",
    "            ## Parameter updates\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_total += loss.item()\n",
    "        tbar.set_description(f\"Train loss: {loss_total / len(dataloader)}\")\n",
    "\n",
    "    return loss_total / len(dataloader)\n",
    "\n",
    "\n",
    "def calculate_test_accuracy(model, transform_fn, dataloader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    tf = nn.Flatten()\n",
    "    for (xi, yi) in dataloader:\n",
    "        xi = transform_fn(xi)\n",
    "        pred = model(xi)\n",
    "        yi_pred = pred.argmax(-1)\n",
    "        y_true.append(yi)\n",
    "        y_pred.append(yi_pred)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "\n",
    "    accuracy = (y_true.squeeze(-1) == y_pred).float().mean()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def calculate_log_loss(model, dataloader):\n",
    "    log_list = []\n",
    "    for (xi, yi) in dataloader:\n",
    "        pred = model(xi)\n",
    "        pred_np = pred.cpu().detach().numpy()\n",
    "        yi_np = yi.cpu().detach().numpy()\n",
    "        logs = np.choose(yi_np.reshape(-1).astype(int), pred_np.T)\n",
    "        log_list.append(np.mean(logs))\n",
    "    return np.mean(np.array(log_list))\n",
    "\n",
    "\n",
    "convnet = Xception_Network(480, 640, num_classes=10)\n",
    "\n",
    "convnet_optimizer = torch.optim.Adam(convnet.parameters(), lr=0.0002)\n",
    "\n",
    "\n",
    "def s(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "loss_functions = [torch.nn.CrossEntropyLoss(), nn.NLLLoss()]\n",
    "\n",
    "train_loop(convnet, s, loss_functions[0], convnet_optimizer, train_dataloader, 10)\n",
    "\n",
    "acc = calculate_test_accuracy(convnet, s, test_dataloader)\n",
    "\n",
    "log_loss = calculate_log_loss(convnet, test_dataloader)\n",
    "\n",
    "print(acc)\n",
    "print(log_loss)\n",
    "\n",
    "test_folder = r\"distraction_data/imgs/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = TensorDataset(tensor_x_test, tensor_y_test)  # create your datset\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=True)  # create your dataloader\n",
    "\n",
    "print(\"Going to train...\")\n",
    "\n",
    "def conv_out_size(slen, kernel_size, stride):\n",
    "    \"\"\"\n",
    "    :param slen: Size length of the image. Should be an int.\n",
    "    :param kernel_size: Int\n",
    "    :param stride: Int\n",
    "    :return: The size length of output after convolution\n",
    "    This function considers 1-dim case.\n",
    "    \"\"\"\n",
    "    return int((slen - kernel_size) / stride + 1)\n",
    "\n",
    "\n",
    "def train_loop(model, transform_fn, loss_fn, optimizer, dataloader, num_epochs):\n",
    "    \"\"\"\n",
    "\n",
    "    :param model:\n",
    "    :param transform_fn:\n",
    "    :param loss_fn:\n",
    "    :param optimizer:\n",
    "    :param dataloader:\n",
    "    :param num_epochs:\n",
    "    :return:\n",
    "\n",
    "    Use this function to train your model.\n",
    "    \"\"\"\n",
    "    tbar = tqdm(range(num_epochs))\n",
    "    for _ in tbar:\n",
    "        loss_total = 0.\n",
    "        for i, (x, y) in enumerate(dataloader):\n",
    "            x = transform_fn(x)\n",
    "            pred = model(x)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            loss = loss_fn(pred, y.squeeze(-1))\n",
    "            # print(pred)\n",
    "            # print(y.squeeze(-1))\n",
    "            ## Parameter updates\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_total += loss.item()\n",
    "        tbar.set_description(f\"Train loss: {loss_total / len(dataloader)}\")\n",
    "\n",
    "    return loss_total / len(dataloader)\n",
    "\n",
    "\n",
    "def calculate_test_accuracy(model, transform_fn, dataloader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    tf = nn.Flatten()\n",
    "    for (xi, yi) in dataloader:\n",
    "        xi = transform_fn(xi)\n",
    "        pred = model(xi)\n",
    "        yi_pred = pred.argmax(-1)\n",
    "        y_true.append(yi)\n",
    "        y_pred.append(yi_pred)\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "\n",
    "    accuracy = (y_true.squeeze(-1) == y_pred).float().mean()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def calculate_log_loss(model, dataloader):\n",
    "    log_list = []\n",
    "    for (xi, yi) in dataloader:\n",
    "        pred = model(xi)\n",
    "        pred_np = pred.cpu().detach().numpy()\n",
    "        yi_np = yi.cpu().detach().numpy()\n",
    "        logs = np.choose(yi_np.reshape(-1).astype(int), pred_np.T)\n",
    "        log_list.append(np.mean(logs))\n",
    "    return np.mean(np.array(log_list))\n",
    "\n",
    "\n",
    "convnet = Xception_Network(480, 640, num_classes=10)\n",
    "\n",
    "convnet_optimizer = torch.optim.Adam(convnet.parameters(), lr=0.0002)\n",
    "\n",
    "\n",
    "def s(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "loss_functions = [torch.nn.CrossEntropyLoss(), nn.NLLLoss()]\n",
    "\n",
    "train_loop(convnet, s, loss_functions[0], convnet_optimizer, train_dataloader, 10)\n",
    "\n",
    "acc = calculate_test_accuracy(convnet, s, test_dataloader)\n",
    "\n",
    "log_loss = calculate_log_loss(convnet, test_dataloader)\n",
    "\n",
    "print(acc)\n",
    "print(log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01644ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1176872/5475407.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  test_x = torch.Tensor([img_frame])\n"
     ]
    }
   ],
   "source": [
    "test_folder = r\"distraction_data/imgs/test\"\n",
    "\n",
    "\n",
    "def predict_images_in_folder(folder, model):\n",
    "    prediction_list = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            img_frame = np.zeros((3, 480, 640))\n",
    "            img_frame[0, :, :] = img[:, :, 0]\n",
    "            img_frame[1, :, :] = img[:, :, 1]\n",
    "            img_frame[2, :, :] = img[:, :, 2]\n",
    "            test_x = torch.Tensor([img_frame])\n",
    "            pred_x = model(test_x)\n",
    "            pred_x = pred_x.cpu().detach().numpy()\n",
    "            pred_x = np.exp(pred_x)\n",
    "            prediction_list.append((filename, pred_x[0].tolist()))\n",
    "    prediction_list = sorted(prediction_list, key=lambda x: x[0])\n",
    "    return prediction_list\n",
    "\n",
    "\n",
    "result = predict_images_in_folder(test_folder, convnet)\n",
    "result = [[x[0], x[1][0], x[1][1], x[1][2], x[1][3], x[1][4], x[1][5], x[1][6], x[1][7], x[1][8], x[1][9]]\n",
    "             for x in result]\n",
    "\n",
    "result_df = pandas.DataFrame(result, columns=['img', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "result_df.to_csv('submission.csv')\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1e422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68b67e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(convnet.state_dict(), 'net_7_14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "027de42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(convnet.state_dict(), 'net_7_14.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed073569",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39msave({\n\u001b[1;32m      2\u001b[0m             \n\u001b[0;32m----> 3\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m      4\u001b[0m             \n\u001b[1;32m      5\u001b[0m             }, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict_7_14.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save({\n",
    "            \n",
    "            'model_state_dict': convnet.state_dict(),\n",
    "            \n",
    "            }, 'state_dict_7_14.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545427a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
